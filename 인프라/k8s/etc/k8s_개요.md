# 쿠버네티스

서버를 배포한 후에 서버가 건강하게 잘 살아있는지 확인하는 운영 업무가 필요하다. 모니터링하고, 트래픽에 따라 서버를 늘려주거나 죽으면 살려주는 등의 작업이 필요하다. 
운영하는 서버의 개수가 많아지면 이 운영 작업이 매우 버거워진다.
컴퓨터의 상태를 모니터링해서 애플리케이션을 적절히 배치해주고, 애플리케이션이 건강하게 서비스할 수 있는지 체크하고 치료해주는 기능이 있으면 얼마나 좋을까
그게 쿠버네티스가 하는 일이다.

-> 애플리케이션의 배포, 관리, 확장을 자동화!

## 도커 컴포즈와의 차이
- 여러 컨테이너를 관리하는 기능은 도커 컴포즈와 큰 차이가 없어보인다. 하지만 큰 차이가 있다.
- 도커컴포즈는 `서버 한대` 안에서 `여러 컨테이너`를 관리하는 기능이다. 
- 쿠버네티스는 `여러 물리 서버`를 `클러스터`로 관리하고, 각 서버 자원을 관리해준다.
- 또한 컨테이너의 자동복구, 모니터링 기능도 제공해주고, 여러 배포 전략, 롤백 기능 또한 제공해준다.
- 여러 서버에 접속해서 여러 개의 도커 또는 도커 컴포즈 파일들을 관리하면서 서버를 운영하는 것은, 쿠버네티스와 비교했을 때 고된 일이다.

## 핵심 개념!
- `desired state` (바람직한 상태, 원하는 상태) 
    - 쿠버는 이 상태를 유지하려고 한다.
- 동작 
    - desired state를 설정
    - 모니터링
    - 상태 비교
    - 자동 복구 및 조정
- 이 작업들이 쿠버가 하는 가장 핵심적인 일이다.

## 구성 요소

### 파드
- 논리적 단위 그룹화
    - 관련 컨테이너들을 하나의 그룹인 파드로 묶는 것
- 쿠버에서 생성, 관리되는 가장 작은 배포 단위
- 파드의 역할과 중요성
    - 파드 안에 있는 컨테이너들 끼리 같은 네트워크 네임스페이스와 스토리지 공유 -> 통신 용이, 데이터 공유 용이
    - 여러 컨테이너들을 그룹으로 관리. 배포, 스케일링 단순화. 동일한 하드웨어 리소스 공유
    - 하나의 IP 주소와 포트 범위를 가짐
    - 파드를 여러 노드에 걸쳐 자동으로 배포할 수 있고, 파드가 죽으면 자동으로 복구(재시작)할 수 있음
- 파드 사용 이유
    - 개별 컨테이너 보다 관리 용이. 특정 작업을 위한 컨테이너들을 묶어서 하나의 단위로 관리 할 수 있음.

### 쿠버 주요 구조

#### 노드
- 노드는 파드를 실행하는 `물리적 또는 가상의 서버`
- 파드는 쿠버의 가장 기본적 배포 단위. 하나 이상의 컨테이너로 구성. 
- 파드 내의 컨테이너들은 공유된 리소스와 정보 가짐.
- 같은 목적을 가지는 컨테이너들을 모아 파드라는 단위로 독립적으로 배포하고 관리. 
- 같은 목적을 가지는 컨테이너끼리 리소스 공유를 효율적으로.

#### 마스터 노드
- 쿠버네티스 클러스터를 제어(제어 허브라고 표현하네!)
- `kubectl cli 프로그램`으로 마스터를 조정하고, 워커 노드를 직접 관리하지 않고 `kubectl`로 마스터 노드에 요청하여 관리

#### 컨트롤 플레인
쿠버 클러스터의 중앙 제어 시스템. 클러스터의 상태를 유지하고, 리소스를 배치하고, 전반적 작업 관리
여러 핵심 컴포넌트들로 구성되어 이들 간의 상호작용으로 클러스터를 관리

- `API 서버(kube-apiserver)`
    - rest api를 제공하여 쿠버네티스 클러스터에 명령 전달
    - 인증, 인가를 통해 리소스에 대한 보안 관리도 해줌
    - 내부 컴포넌트끼리도 API를 사용하여 통신이 이뤄짐. 통신의 일관성 보장
    - 메니페스트 파일에 대한 유효성 검사도 해줌
    - 예) kubectl apply -f deployment.yaml 로 새로운 deployment 생성 요청, `API 서버`는 해당 요청을 받아 유효성을 검토하고 클러스터에 배포를 적용함
- `컨트롤러 매니저`
    - 클러스터의 상태를 `원하는 상태`로 유지하는 역할
    - 백그라운드에 따로 실행되는 프로세스
    - 리소스를 지속적으로 모니터링하고 이를 유지하는 역할
    - 하는 역할
        - 복제 컨트롤러(Replication Controller)
            - 파드 개수 유지
        - 엔드 포인트 컨트롤러(Endpoint Controller)
            - 서비스와 파드간 연결 관리
            - 서비스 디스커버리 및 로드 밸런싱 관리 
        - 네임스페이스 컨트롤러(Namespace Controller)
            - 네임스페이스 생성 및 삭제
        - 노드 컨트롤러(Node Controller)
            - 노드 상태 모니터링
            - 장애 감지하고 처리
        - 자원관리
            - 리소스 상태를 정의된 대로 유지되도록 보장
    - 예) deployment가 3개의 파드를 실행해야 함. 실제로 2개 실행 중. `복제 컨트롤러`가 이를 감지하고 새로운 파드를 생성해서 원하는 상태를 유지함
- `스케줄러`
    - 새롭게 생성한 파드를 워커 노드에 적절히 배치
    - 리소스와 노드 상태 고려(존이나 리전도 반영해서 배치)
    - 예) 새로 생성된 파드가 실행될 때 `스케줄러`는 각 노드의 리소스를 평가하고 가장 적합한 노드에 파드를 배치
- `클라우드 컨트롤러 매니저`
    - 클라우드 서비스 제공업체(AWS, GCP, Azure 등) 간의 통합 담당
    - 클라우드 환경에서 클러스터가 실행될 때, 클라우드 리소스와 쿠버 리소스 간 상호작용 관리
    - 예) `클라우드 컨트롤러 매니저`는 AWS의 로드 밸런서, 스토리지 볼륨과 같은 기능을 쿠버 기능과 연동하여 자동으로 설정하고 관리 함
- `etcd`
    - 쿠버의 분산 `key-value` 저장소
    - 모든 상태와 메타데이터를 저장
    - 모든 클러스터 데이터는 etcd에 저장
    - `Single Source of Truth`
        - 쿠버의 유일한 중앙 데이터 저장소
        - 단일 출처
    - 강력한 일관성을 보장하기 위해 트랜잭션 기반으로 데이터를 저장
    - 데이터 복제를 통해 고가용성 지원. 데이터 손실 방지
    - 예) 새로운 파드 실행 시 쿠버는 이 정보를 `etcd`에 기록. 이후 api 서버나 다른 컴포넌트들은 etcd에서 정보를 읽어 클러스터 상태를 확인함

#### 워커 노드
- 실제 애플리케이션 컨테이너가 실행되는 서버
- `워커 노드`의 컴포넌트
    - `kubelet`
        - 컨테이너가 파드 내에서 올바르게 실행되도록 관리
        - 파드의 상태를 모니터링해서 `kube-scheulder`에 통지
    - `kube-proxy`
        - `네트워크 프록시` 및 `로드 밸런서` 역할
        - 노드의 네트워크 규칙을 관리
        - 연결 및 트래픽 라우팅 처리
    - `컨테이너 런타임`
        - 컨테이너 실행 환경
        - ex) Dokcer, containerd, CRI-O

#### 파드의 구성 요소와 특징
- 컨테이너
    - 파드는 하나 이상의 컨테이너 포함
    - 동일한 네트워크 및 UTS(Unix Time Sharing) 네임스페이스 공유
    - IPC 통신 가능
    - 일반적으로 하나의 파드에는 하나의 애플리케이션 컨테이너 실행. 추가로 사이드카 컨테이너 포함 가능. 사이드카 컨테이너는 로깅, 모니터링, 네트워크 프로시 등의 보조 기능 제공
- 공유 네트워크
    - 파드 안에 있는 모든 컨테이너는 동일 IP 주소와 포트 공간 공유
    - 파드에 접근시 마치 하나의 엔티티 처럼 보이게 함
    - 파드 내 컨테이너 간 통신을 로컬 호스트를 통해 가능하게 함
- 공유 스토리지 볼륨
    - 파드는 하나 이상의 볼륨을 정의할 수 있음
    - 파드 내의 컨테이너 사이에 공유. 파일 시스템을 통한 데이터 공유 용이
    - 쿠버는 다양한 유형의 볼륨 지원(AWS EBS, Azure Disk). 파드가 스토리지에 종속되지 않고, 어떤 노드에서든 동일하게 작동될 수 있게 함
- 생명주기와 관리
    - 파드는 `불변성`을 가짐
    - 파드 내부 컨테이너 변경 불가. 컨테이너 업데이트가 필요하면 파드를 새로 생성하고 교체해야 함
    - 파드는 `복제(replication)`를 통해 고가용성 보장 받음
    - 쿠버는 파드의 상태를 모니터링하고 실패한 파드를 자동으로 대체하는 `복제 컨트롤러`나 `레플리카셋`을 사용해서 관리

### 쿠버 특징
- Self-healing
    - 실패한 컨테이너를 다시 시작하고 교체. 상태 검사에 응답하지 않으면 죽임. 
    - 이 모든 과정을 클라이언트에게 보여주지 않음
- auto scaling
    - 시스템이 자동으로 파드 수 조정
        - 비용 최적화!!
    - 변화하는 워크로드에 따라 리소스 충족 기능
    - Horizontal Pod Autoscaler (HPA)
        - 파드 인스턴스 수를 자동으로 스케일 아웃
    - Cluster Autoscaler
        - 노드 수를 동적 조정
        - 예) 노드 수 포화 -> 노드 추가
- Automated rollouts and rollbacks
    - 배포 자동화
    - 필용한 경우 롤백 
    - automated rollouts
        - 롤아웃: 새로운 버전을 점진적으로 적용하는 과정
        - 중간에 문제 발생시 배포 중지
    - automated rollbacks
        - 롤백: 배포에 실패하거나 문제 발생시 이전 버전으로 돌리는 과정
    - CICD 파이프라인 일부로서 매우 유용
        - 배포를 안전하게 자주 할 수 있게 됨
        - 문제 발생시 빠르게 이전 상태 복구 가능

---

# 참고 
- [플랫 네트워크](https://knight76.tistory.com/entry/%ED%94%8C%EB%9E%AB-%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%ACflat-network-%EB%9E%80)